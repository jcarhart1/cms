{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 2604720,
     "sourceType": "datasetVersion",
     "datasetId": 1583027
    },
    {
     "sourceId": 2701830,
     "sourceType": "datasetVersion",
     "datasetId": 1645661
    },
    {
     "sourceId": 2714421,
     "sourceType": "datasetVersion",
     "datasetId": 1653824
    }
   ],
   "dockerImageVersionId": 30138,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CareHarmony Case Study\n",
    "\n",
    "You will be using the CMS 2008-2010 Data Entrepreneurs Synthetic PUF beneficiary data files for this project. This dataset is a bit old, but it is a large synthetic dataset that closely mirrors the type of data that we work with. Due to file size limitations, each data type in the CMS Linkable 2008-2010 Medicare DE-SynPUF is released in 20 separate samples (essentially each is a .25% sample)\n",
    "\n",
    "The DE-SynPUF contains five types of data for the period 2008-2010:\n",
    "* Beneficiary Summary\n",
    "* Inpatient Claims\n",
    "* Outpatient Claims\n",
    "* Carrier Claims (not included in the current analysis)\n",
    "* Prescription Drug Events (not included in the current analysis)\n",
    "\n",
    "\n",
    "To keep things simple, you will be primarily utilizing the beneficiary-level files that can be found in the zip file attached. These data files contain high-level summaries of patient demographics, conditions, and spending for each of the years 2008, 2009, and 2010. It is organized into twenty separate files for each year and organized such that the same patients are retained in each of the yearly files sharing the same index number. Ten files per year are included for completeness, but you may use as many as you like to conduct your analysis. Note that the dataset is indeed synthetic so many relationships we would expect to see in real world data may not hold. Accordingly, in our evaluation we will focus more on your analytical approach than the actual results.\n",
    "\n",
    "The original source of the files can be found at this link: https://www.cms.gov/Research-Statistics-Data-and-Systems/Downloadable-Public-Use-Files/SynPUFs/DESample01. Translations for a lot of the common terms provided in the Beneficiary Summary file can be found at this link: https://www.cms.gov/files/document/de-10-codebook.pdf-0."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CareHarmony Case Study: predictive modeling\n",
    "\n",
    "The health system is interested in identifying and prioritizing patients who are at risk of experiencing a spike in costs in 2011. Use the beneficiary data from 2008-2010 to develop a model to address this concern and explain how you would use it to select a set of patients to prioritize in 2011. Please also make sure to explain your model selection and validation procedure."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Beneficiary data processing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique IDs in 2008: 2210481\n",
      "Unique IDs in 2009: 2176679\n",
      "Unique IDs in 2010: 2142287\n",
      "Unique IDs after merging: 2142287\n",
      "First few rows of the merged DataFrame:\n",
      "        DESYNPUF_ID BENE_BIRTH_DT_2008  BENE_SEX_IDENT_CD_2008  \\\n",
      "0  00013D2EFD8E45D1         1923-05-01                       1   \n",
      "1  00016F745862898F         1943-01-01                       1   \n",
      "2  0001FDD721E223DC         1936-09-01                       2   \n",
      "3  00021CA6FF03E670         1941-06-01                       1   \n",
      "4  00024B3D2352D2D0         1936-08-01                       1   \n",
      "\n",
      "   BENE_RACE_CD_2008  BENE_ESRD_IND_2008  SP_STATE_CODE_2008  \\\n",
      "0                  1                   2                  26   \n",
      "1                  1                   2                  39   \n",
      "2                  1                   2                  39   \n",
      "3                  5                   2                   6   \n",
      "4                  1                   2                  52   \n",
      "\n",
      "   BENE_COUNTY_CD_2008  SP_ALZHDMTA_2008  SP_CHF_2008  SP_CHRNKIDN_2008  ...  \\\n",
      "0                  950                 2            2                 2  ...   \n",
      "1                  230                 2            2                 2  ...   \n",
      "2                  280                 2            2                 2  ...   \n",
      "3                  290                 2            2                 2  ...   \n",
      "4                  590                 2            2                 2  ...   \n",
      "\n",
      "   MEDREIMB_IP_2010  BENRES_IP_2010  PPPYMT_IP_2010  MEDREIMB_OP_2010  \\\n",
      "0            4000.0          1100.0             0.0               0.0   \n",
      "1           16000.0          1100.0             0.0               0.0   \n",
      "2               0.0             0.0             0.0               0.0   \n",
      "3               0.0             0.0             0.0               0.0   \n",
      "4               0.0             0.0             0.0              40.0   \n",
      "\n",
      "   BENRES_OP_2010  PPPYMT_OP_2010  MEDREIMB_CAR_2010  BENRES_CAR_2010  \\\n",
      "0             0.0             0.0               90.0             30.0   \n",
      "1             0.0             0.0              930.0            150.0   \n",
      "2             0.0             0.0                0.0              0.0   \n",
      "3             0.0             0.0                0.0              0.0   \n",
      "4             0.0             0.0              590.0             60.0   \n",
      "\n",
      "   PPPYMT_CAR_2010  Age  \n",
      "0              0.0  101  \n",
      "1              0.0   81  \n",
      "2              0.0   87  \n",
      "3              0.0   83  \n",
      "4              0.0   87  \n",
      "\n",
      "[5 rows x 70 columns]\n",
      "The code block took 115.11509132385254 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Define the base directory for our CSV files\n",
    "base_dir = r'C:\\code_personal_use\\cms\\data\\bene'\n",
    "\n",
    "# List of years we have data for\n",
    "years = [2008, 2009, 2010]\n",
    "\n",
    "# Columns to use for each year\n",
    "columns_2008 = [\n",
    "    'DESYNPUF_ID', 'BENE_BIRTH_DT', 'BENE_SEX_IDENT_CD', 'BENE_RACE_CD',\n",
    "    'SP_STATE_CODE', 'BENE_COUNTY_CD', 'SP_ALZHDMTA', 'SP_CHF', 'SP_CHRNKIDN',\n",
    "    'SP_CNCR', 'BENE_ESRD_IND', 'SP_COPD', 'SP_DEPRESSN', 'SP_DIABETES',\n",
    "    'SP_ISCHMCHT', 'SP_OSTEOPRS', 'SP_RA_OA', 'SP_STRKETIA', 'MEDREIMB_IP',\n",
    "    'BENRES_IP', 'PPPYMT_IP', 'MEDREIMB_OP', 'BENRES_OP', 'PPPYMT_OP',\n",
    "    'MEDREIMB_CAR', 'BENRES_CAR', 'PPPYMT_CAR'\n",
    "]\n",
    "\n",
    "columns_2009_2010 = [\n",
    "    'DESYNPUF_ID', 'SP_ALZHDMTA', 'SP_CHF', 'SP_CHRNKIDN', 'SP_CNCR',\n",
    "    'BENE_ESRD_IND', 'SP_COPD', 'SP_DEPRESSN', 'SP_DIABETES', 'SP_ISCHMCHT',\n",
    "    'SP_OSTEOPRS', 'SP_RA_OA', 'SP_STRKETIA', 'MEDREIMB_IP', 'BENRES_IP',\n",
    "    'PPPYMT_IP', 'MEDREIMB_OP', 'BENRES_OP', 'PPPYMT_OP', 'MEDREIMB_CAR',\n",
    "    'BENRES_CAR', 'PPPYMT_CAR'\n",
    "]\n",
    "\n",
    "# Function to recode BENE_ESRD_IND\n",
    "def recode_bene_esrd_ind(df, column):\n",
    "    df[column] = df[column].replace({'Y': 1, '0': 2}).astype(int)\n",
    "    return df\n",
    "\n",
    "# Function to rename columns with a suffix\n",
    "def rename_columns_with_suffix(df, suffix):\n",
    "    df = df.rename(columns=lambda x: x + suffix if x != 'DESYNPUF_ID' else x)\n",
    "    return df\n",
    "\n",
    "# Function to load and preprocess a batch of files for a given year\n",
    "def load_and_preprocess_batch(file_paths, year):\n",
    "    columns = columns_2008 if year == 2008 else columns_2009_2010\n",
    "    parse_dates = ['BENE_BIRTH_DT'] if year == 2008 else None\n",
    "    date_parser = lambda x: pd.to_datetime(x, format='%Y%m%d') if year == 2008 else None\n",
    "\n",
    "    # Load and preprocess files in the batch\n",
    "    dfs = []\n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(\n",
    "            file_path,\n",
    "            usecols=columns,\n",
    "            parse_dates=parse_dates,\n",
    "            date_parser=date_parser\n",
    "        )\n",
    "        df = recode_bene_esrd_ind(df, 'BENE_ESRD_IND')\n",
    "        df = rename_columns_with_suffix(df, f'_{year}')\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames in the batch\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Create a dictionary to store DataFrames for each year\n",
    "dfs_by_year = {}\n",
    "\n",
    "# Process files in batches\n",
    "batch_size = 5  # Adjust the batch size based on your system's memory\n",
    "for year in years:\n",
    "    file_paths = [os.path.join(base_dir, f'DE1_0_{year}_Beneficiary_Summary_File_Sample_{i}.csv') for i in range(1, 20)]\n",
    "    batches = [file_paths[i:i + batch_size] for i in range(0, len(file_paths), batch_size)]\n",
    "\n",
    "    # Load and preprocess each batch\n",
    "    year_dfs = []\n",
    "    for batch in batches:\n",
    "        batch_df = load_and_preprocess_batch(batch, year)\n",
    "        year_dfs.append(batch_df)\n",
    "\n",
    "    # Concatenate all batches for the year\n",
    "    dfs_by_year[year] = pd.concat(year_dfs, ignore_index=True)\n",
    "\n",
    "# Merge DataFrames for all years on DESYNPUF_ID\n",
    "merged_df = dfs_by_year[2008]\n",
    "for year in years[1:]:\n",
    "    merged_df = merged_df.merge(dfs_by_year[year], on='DESYNPUF_ID', how='inner')\n",
    "\n",
    "# Define the prefixes to check for null values\n",
    "prefixes = [\n",
    "    'MEDREIMB_IP', 'BENRES_IP', 'PPPYMT_IP', 'MEDREIMB_OP', 'BENRES_OP',\n",
    "    'PPPYMT_OP', 'MEDREIMB_CAR', 'BENRES_CAR', 'PPPYMT_CAR'\n",
    "]\n",
    "\n",
    "# Function to replace null values with 0 for specified prefixes\n",
    "def replace_nulls_with_zero(df, prefixes):\n",
    "    for prefix in prefixes:\n",
    "        cols = [col for col in df.columns if col.startswith(prefix)]\n",
    "        df[cols] = df[cols].fillna(0)\n",
    "    return df\n",
    "\n",
    "merged_df = replace_nulls_with_zero(merged_df, prefixes)\n",
    "\n",
    "# Calculate Age\n",
    "def calculate_age(birth_date, reference_date):\n",
    "    return reference_date.year - birth_date.year - ((reference_date.month, reference_date.day) < (birth_date.month, birth_date.day))\n",
    "\n",
    "reference_date = datetime.now()  # Using the current date as the reference date\n",
    "merged_df['Age'] = merged_df['BENE_BIRTH_DT_2008'].apply(lambda x: calculate_age(x, reference_date))\n",
    "\n",
    "# Display the first few rows of the resulting DataFrame and unique ID counts\n",
    "print(f'Unique IDs in 2008: {dfs_by_year[2008][\"DESYNPUF_ID\"].nunique()}')\n",
    "print(f'Unique IDs in 2009: {dfs_by_year[2009][\"DESYNPUF_ID\"].nunique()}')\n",
    "print(f'Unique IDs in 2010: {dfs_by_year[2010][\"DESYNPUF_ID\"].nunique()}')\n",
    "print(f'Unique IDs after merging: {merged_df[\"DESYNPUF_ID\"].nunique()}')\n",
    "\n",
    "print(\"First few rows of the merged DataFrame:\")\n",
    "print(merged_df.head())\n",
    "\n",
    "stop_time = time.time()\n",
    "print(\"The code block took {0} seconds to run.\".format(stop_time - start_time))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "merged_df.info()"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.status.busy": "2021-10-18T04:32:09.367649Z",
     "iopub.execute_input": "2021-10-18T04:32:09.368574Z",
     "iopub.status.idle": "2021-10-18T04:32:09.473489Z",
     "shell.execute_reply.started": "2021-10-18T04:32:09.368526Z",
     "shell.execute_reply": "2021-10-18T04:32:09.47243Z"
    },
    "trusted": true
   },
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2142287 entries, 0 to 2142286\n",
      "Data columns (total 70 columns):\n",
      " #   Column                  Dtype         \n",
      "---  ------                  -----         \n",
      " 0   DESYNPUF_ID             object        \n",
      " 1   BENE_BIRTH_DT_2008      datetime64[ns]\n",
      " 2   BENE_SEX_IDENT_CD_2008  int64         \n",
      " 3   BENE_RACE_CD_2008       int64         \n",
      " 4   BENE_ESRD_IND_2008      int32         \n",
      " 5   SP_STATE_CODE_2008      int64         \n",
      " 6   BENE_COUNTY_CD_2008     int64         \n",
      " 7   SP_ALZHDMTA_2008        int64         \n",
      " 8   SP_CHF_2008             int64         \n",
      " 9   SP_CHRNKIDN_2008        int64         \n",
      " 10  SP_CNCR_2008            int64         \n",
      " 11  SP_COPD_2008            int64         \n",
      " 12  SP_DEPRESSN_2008        int64         \n",
      " 13  SP_DIABETES_2008        int64         \n",
      " 14  SP_ISCHMCHT_2008        int64         \n",
      " 15  SP_OSTEOPRS_2008        int64         \n",
      " 16  SP_RA_OA_2008           int64         \n",
      " 17  SP_STRKETIA_2008        int64         \n",
      " 18  MEDREIMB_IP_2008        float64       \n",
      " 19  BENRES_IP_2008          float64       \n",
      " 20  PPPYMT_IP_2008          float64       \n",
      " 21  MEDREIMB_OP_2008        float64       \n",
      " 22  BENRES_OP_2008          float64       \n",
      " 23  PPPYMT_OP_2008          float64       \n",
      " 24  MEDREIMB_CAR_2008       float64       \n",
      " 25  BENRES_CAR_2008         float64       \n",
      " 26  PPPYMT_CAR_2008         float64       \n",
      " 27  BENE_ESRD_IND_2009      int32         \n",
      " 28  SP_ALZHDMTA_2009        int64         \n",
      " 29  SP_CHF_2009             int64         \n",
      " 30  SP_CHRNKIDN_2009        int64         \n",
      " 31  SP_CNCR_2009            int64         \n",
      " 32  SP_COPD_2009            int64         \n",
      " 33  SP_DEPRESSN_2009        int64         \n",
      " 34  SP_DIABETES_2009        int64         \n",
      " 35  SP_ISCHMCHT_2009        int64         \n",
      " 36  SP_OSTEOPRS_2009        int64         \n",
      " 37  SP_RA_OA_2009           int64         \n",
      " 38  SP_STRKETIA_2009        int64         \n",
      " 39  MEDREIMB_IP_2009        float64       \n",
      " 40  BENRES_IP_2009          float64       \n",
      " 41  PPPYMT_IP_2009          float64       \n",
      " 42  MEDREIMB_OP_2009        float64       \n",
      " 43  BENRES_OP_2009          float64       \n",
      " 44  PPPYMT_OP_2009          float64       \n",
      " 45  MEDREIMB_CAR_2009       float64       \n",
      " 46  BENRES_CAR_2009         float64       \n",
      " 47  PPPYMT_CAR_2009         float64       \n",
      " 48  BENE_ESRD_IND_2010      int32         \n",
      " 49  SP_ALZHDMTA_2010        int64         \n",
      " 50  SP_CHF_2010             int64         \n",
      " 51  SP_CHRNKIDN_2010        int64         \n",
      " 52  SP_CNCR_2010            int64         \n",
      " 53  SP_COPD_2010            int64         \n",
      " 54  SP_DEPRESSN_2010        int64         \n",
      " 55  SP_DIABETES_2010        int64         \n",
      " 56  SP_ISCHMCHT_2010        int64         \n",
      " 57  SP_OSTEOPRS_2010        int64         \n",
      " 58  SP_RA_OA_2010           int64         \n",
      " 59  SP_STRKETIA_2010        int64         \n",
      " 60  MEDREIMB_IP_2010        float64       \n",
      " 61  BENRES_IP_2010          float64       \n",
      " 62  PPPYMT_IP_2010          float64       \n",
      " 63  MEDREIMB_OP_2010        float64       \n",
      " 64  BENRES_OP_2010          float64       \n",
      " 65  PPPYMT_OP_2010          float64       \n",
      " 66  MEDREIMB_CAR_2010       float64       \n",
      " 67  BENRES_CAR_2010         float64       \n",
      " 68  PPPYMT_CAR_2010         float64       \n",
      " 69  Age                     int64         \n",
      "dtypes: datetime64[ns](1), float64(27), int32(3), int64(38), object(1)\n",
      "memory usage: 1.1+ GB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "       BENE_SEX_IDENT_CD_2008  BENE_RACE_CD_2008  BENE_ESRD_IND_2008  \\\ncount            2.142287e+06       2.142287e+06        2.142287e+06   \nmean             1.555706e+00       1.284521e+00        1.929264e+00   \nstd              4.968873e-01       7.543183e-01        2.563828e-01   \nmin              1.000000e+00       1.000000e+00        1.000000e+00   \n50%              2.000000e+00       1.000000e+00        2.000000e+00   \nmax              2.000000e+00       5.000000e+00        2.000000e+00   \n\n       SP_STATE_CODE_2008  BENE_COUNTY_CD_2008  SP_ALZHDMTA_2008  \\\ncount        2.142287e+06         2.142287e+06      2.142287e+06   \nmean         2.572132e+01         3.655592e+02      1.807819e+00   \nstd          1.557189e+01         2.661676e+02      3.940147e-01   \nmin          1.000000e+00         0.000000e+00      1.000000e+00   \n50%          2.500000e+01         3.300000e+02      2.000000e+00   \nmax          5.400000e+01         9.990000e+02      2.000000e+00   \n\n        SP_CHF_2008  SP_CHRNKIDN_2008  SP_CNCR_2008  SP_COPD_2008  ...  \\\ncount  2.142287e+06      2.142287e+06  2.142287e+06  2.142287e+06  ...   \nmean   1.715481e+00      1.839042e+00  1.936368e+00  1.864491e+00  ...   \nstd    4.511853e-01      3.674926e-01  2.440971e-01  3.422669e-01  ...   \nmin    1.000000e+00      1.000000e+00  1.000000e+00  1.000000e+00  ...   \n50%    2.000000e+00      2.000000e+00  2.000000e+00  2.000000e+00  ...   \nmax    2.000000e+00      2.000000e+00  2.000000e+00  2.000000e+00  ...   \n\n       MEDREIMB_IP_2010  BENRES_IP_2010  PPPYMT_IP_2010  MEDREIMB_OP_2010  \\\ncount      2.142287e+06    2.142287e+06    2.142287e+06      2.142287e+06   \nmean       1.244053e+03    1.448212e+02    5.237660e+01      4.336826e+02   \nstd        5.141761e+03    5.655884e+02    1.379283e+03      1.273109e+03   \nmin       -8.000000e+03    0.000000e+00    0.000000e+00     -1.000000e+02   \n50%        0.000000e+00    0.000000e+00    0.000000e+00      0.000000e+00   \nmax        1.566900e+05    3.730000e+04    8.300000e+04      4.051000e+04   \n\n       BENRES_OP_2010  PPPYMT_OP_2010  MEDREIMB_CAR_2010  BENRES_CAR_2010  \\\ncount    2.142287e+06    2.142287e+06       2.142287e+06     2.142287e+06   \nmean     1.314106e+02    1.503832e+01       8.477981e+02     2.394512e+02   \nstd      3.680647e+02    2.774419e+02       9.995214e+02     2.843982e+02   \nmin      0.000000e+00    0.000000e+00       0.000000e+00     0.000000e+00   \n50%      0.000000e+00    0.000000e+00       5.400000e+02     1.500000e+02   \nmax      1.104000e+04    1.800000e+04       1.653000e+04     3.590000e+03   \n\n       PPPYMT_CAR_2010           Age  \ncount     2.142287e+06  2.142287e+06  \nmean      1.284738e+01  8.713659e+01  \nstd       7.319756e+01  1.258293e+01  \nmin       0.000000e+00  4.000000e+01  \n50%       0.000000e+00  8.800000e+01  \nmax       3.000000e+03  1.150000e+02  \n\n[6 rows x 68 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BENE_SEX_IDENT_CD_2008</th>\n      <th>BENE_RACE_CD_2008</th>\n      <th>BENE_ESRD_IND_2008</th>\n      <th>SP_STATE_CODE_2008</th>\n      <th>BENE_COUNTY_CD_2008</th>\n      <th>SP_ALZHDMTA_2008</th>\n      <th>SP_CHF_2008</th>\n      <th>SP_CHRNKIDN_2008</th>\n      <th>SP_CNCR_2008</th>\n      <th>SP_COPD_2008</th>\n      <th>...</th>\n      <th>MEDREIMB_IP_2010</th>\n      <th>BENRES_IP_2010</th>\n      <th>PPPYMT_IP_2010</th>\n      <th>MEDREIMB_OP_2010</th>\n      <th>BENRES_OP_2010</th>\n      <th>PPPYMT_OP_2010</th>\n      <th>MEDREIMB_CAR_2010</th>\n      <th>BENRES_CAR_2010</th>\n      <th>PPPYMT_CAR_2010</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2.142287e+06</td>\n      <td>2.142287e+06</td>\n      <td>2.142287e+06</td>\n      <td>2.142287e+06</td>\n      <td>2.142287e+06</td>\n      <td>2.142287e+06</td>\n      <td>2.142287e+06</td>\n      <td>2.142287e+06</td>\n      <td>2.142287e+06</td>\n      <td>2.142287e+06</td>\n      <td>...</td>\n      <td>2.142287e+06</td>\n      <td>2.142287e+06</td>\n      <td>2.142287e+06</td>\n      <td>2.142287e+06</td>\n      <td>2.142287e+06</td>\n      <td>2.142287e+06</td>\n      <td>2.142287e+06</td>\n      <td>2.142287e+06</td>\n      <td>2.142287e+06</td>\n      <td>2.142287e+06</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.555706e+00</td>\n      <td>1.284521e+00</td>\n      <td>1.929264e+00</td>\n      <td>2.572132e+01</td>\n      <td>3.655592e+02</td>\n      <td>1.807819e+00</td>\n      <td>1.715481e+00</td>\n      <td>1.839042e+00</td>\n      <td>1.936368e+00</td>\n      <td>1.864491e+00</td>\n      <td>...</td>\n      <td>1.244053e+03</td>\n      <td>1.448212e+02</td>\n      <td>5.237660e+01</td>\n      <td>4.336826e+02</td>\n      <td>1.314106e+02</td>\n      <td>1.503832e+01</td>\n      <td>8.477981e+02</td>\n      <td>2.394512e+02</td>\n      <td>1.284738e+01</td>\n      <td>8.713659e+01</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>4.968873e-01</td>\n      <td>7.543183e-01</td>\n      <td>2.563828e-01</td>\n      <td>1.557189e+01</td>\n      <td>2.661676e+02</td>\n      <td>3.940147e-01</td>\n      <td>4.511853e-01</td>\n      <td>3.674926e-01</td>\n      <td>2.440971e-01</td>\n      <td>3.422669e-01</td>\n      <td>...</td>\n      <td>5.141761e+03</td>\n      <td>5.655884e+02</td>\n      <td>1.379283e+03</td>\n      <td>1.273109e+03</td>\n      <td>3.680647e+02</td>\n      <td>2.774419e+02</td>\n      <td>9.995214e+02</td>\n      <td>2.843982e+02</td>\n      <td>7.319756e+01</td>\n      <td>1.258293e+01</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>...</td>\n      <td>-8.000000e+03</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>-1.000000e+02</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>4.000000e+01</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>2.000000e+00</td>\n      <td>2.500000e+01</td>\n      <td>3.300000e+02</td>\n      <td>2.000000e+00</td>\n      <td>2.000000e+00</td>\n      <td>2.000000e+00</td>\n      <td>2.000000e+00</td>\n      <td>2.000000e+00</td>\n      <td>...</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>5.400000e+02</td>\n      <td>1.500000e+02</td>\n      <td>0.000000e+00</td>\n      <td>8.800000e+01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2.000000e+00</td>\n      <td>5.000000e+00</td>\n      <td>2.000000e+00</td>\n      <td>5.400000e+01</td>\n      <td>9.990000e+02</td>\n      <td>2.000000e+00</td>\n      <td>2.000000e+00</td>\n      <td>2.000000e+00</td>\n      <td>2.000000e+00</td>\n      <td>2.000000e+00</td>\n      <td>...</td>\n      <td>1.566900e+05</td>\n      <td>3.730000e+04</td>\n      <td>8.300000e+04</td>\n      <td>4.051000e+04</td>\n      <td>1.104000e+04</td>\n      <td>1.800000e+04</td>\n      <td>1.653000e+04</td>\n      <td>3.590000e+03</td>\n      <td>3.000000e+03</td>\n      <td>1.150000e+02</td>\n    </tr>\n  </tbody>\n</table>\n<p>6 rows × 68 columns</p>\n</div>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.describe(())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Need to work on optimizing this step. It currently takes a little over 5 mins of run time to finish merging all 20 beneficiary files"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JoeCarhart\\AppData\\Local\\Temp\\ipykernel_18260\\348429611.py:49: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_long['Column'] = df_long['Year_Column'].str.replace(r'_\\d{4}$', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wide format DataFrame:\n",
      "        DESYNPUF_ID BENE_BIRTH_DT_2008  BENE_SEX_IDENT_CD_2008  \\\n",
      "0  00013D2EFD8E45D1         1923-05-01                       1   \n",
      "1  00016F745862898F         1943-01-01                       1   \n",
      "2  0001FDD721E223DC         1936-09-01                       2   \n",
      "3  00021CA6FF03E670         1941-06-01                       1   \n",
      "4  00024B3D2352D2D0         1936-08-01                       1   \n",
      "\n",
      "   BENE_RACE_CD_2008  BENE_ESRD_IND_2008  SP_STATE_CODE_2008  \\\n",
      "0                  1                   2                  26   \n",
      "1                  1                   2                  39   \n",
      "2                  1                   2                  39   \n",
      "3                  5                   2                   6   \n",
      "4                  1                   2                  52   \n",
      "\n",
      "   BENE_COUNTY_CD_2008  SP_ALZHDMTA_2008  SP_CHF_2008  SP_CHRNKIDN_2008  ...  \\\n",
      "0                  950                 2            2                 2  ...   \n",
      "1                  230                 2            2                 2  ...   \n",
      "2                  280                 2            2                 2  ...   \n",
      "3                  290                 2            2                 2  ...   \n",
      "4                  590                 2            2                 2  ...   \n",
      "\n",
      "   MEDREIMB_IP_SUM  BENRES_IP_SUM  PPPYMT_IP_SUM  MEDREIMB_OP_SUM  \\\n",
      "0           4000.0         1100.0            0.0             50.0   \n",
      "1          52000.0         4304.0            0.0             60.0   \n",
      "2              0.0            0.0            0.0             30.0   \n",
      "3              0.0            0.0            0.0              0.0   \n",
      "4              0.0            0.0            0.0            160.0   \n",
      "\n",
      "   BENRES_OP_SUM  PPPYMT_OP_SUM  MEDREIMB_CAR_SUM  BENRES_CAR_SUM  \\\n",
      "0           10.0            0.0             190.0            50.0   \n",
      "1           70.0            0.0            2980.0           920.0   \n",
      "2           50.0            0.0              20.0             0.0   \n",
      "3            0.0            0.0              90.0            10.0   \n",
      "4           80.0            0.0            1220.0           280.0   \n",
      "\n",
      "   PPPYMT_CAR_SUM  total_sum  \n",
      "0             0.0     5400.0  \n",
      "1           100.0    60434.0  \n",
      "2             0.0      100.0  \n",
      "3             0.0      100.0  \n",
      "4             0.0     1740.0  \n",
      "\n",
      "[5 rows x 80 columns]\n",
      "\n",
      "Long format DataFrame:\n",
      "        DESYNPUF_ID  Year  annual_cost Birth_Date  Age  Gender  Race  State  \\\n",
      "0  00000B48BCF4AD29  2008      93452.0 1923-09-01  100       2     5     10   \n",
      "1  00000B48BCF4AD29  2009       8750.0 1923-09-01  100       2     5     10   \n",
      "2  00000B48BCF4AD29  2010       5890.0 1923-09-01  100       2     5     10   \n",
      "3  0000141F2FECE9BC  2008          0.0 1974-04-01   50       2     1     39   \n",
      "4  0000141F2FECE9BC  2009       5308.0 1974-04-01   50       2     1     39   \n",
      "\n",
      "   County  \n",
      "0     260  \n",
      "1     260  \n",
      "2     260  \n",
      "3     560  \n",
      "4     560  \n",
      "The code block took 424.3824224472046 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Filter to include only the specific DESYNPUF_ID for EDA and QA\n",
    "# merged_df = merged_df[merged_df['DESYNPUF_ID'] == '00016F745862898F']\n",
    "\n",
    "# List of columns to sum across years\n",
    "columns_to_sum = [\n",
    "    'MEDREIMB_IP', 'BENRES_IP', 'PPPYMT_IP',\n",
    "    'MEDREIMB_OP', 'BENRES_OP', 'PPPYMT_OP',\n",
    "    'MEDREIMB_CAR', 'BENRES_CAR', 'PPPYMT_CAR'\n",
    "]\n",
    "\n",
    "# Loop through each column and create a new column for the sum across the three years\n",
    "for col in columns_to_sum:\n",
    "    merged_df[col + '_SUM'] = merged_df[col + '_2008'] + merged_df[col + '_2009'] + merged_df[col + '_2010']\n",
    "\n",
    "# Create a list of columns that end with '_SUM'\n",
    "sum_columns = [col + '_SUM' for col in columns_to_sum]\n",
    "\n",
    "# Add a new column 'total_sum' that sums all columns ending with '_SUM'\n",
    "merged_df['total_sum'] = merged_df[sum_columns].sum(axis=1)\n",
    "\n",
    "# Extract additional columns from the 2008 dataset to serve as our demographic features\n",
    "additional_columns_08 = merged_df[['DESYNPUF_ID', 'BENE_BIRTH_DT_2008', 'Age', 'BENE_SEX_IDENT_CD_2008', 'BENE_RACE_CD_2008', 'SP_STATE_CODE_2008', 'BENE_COUNTY_CD_2008']]\n",
    "# Rename columns to more human-readable names\n",
    "additional_columns_08 = additional_columns_08.rename(columns={\n",
    "    'BENE_BIRTH_DT_2008': 'Birth_Date',\n",
    "    'BENE_SEX_IDENT_CD_2008': 'Gender',\n",
    "    'BENE_RACE_CD_2008': 'Race',\n",
    "    'SP_STATE_CODE_2008': 'State',\n",
    "    'BENE_COUNTY_CD_2008': 'County'\n",
    "})\n",
    "\n",
    "# Export the wide format DataFrame to a CSV file for QA\n",
    "# output_path_wide = r'C:\\Users\\JoeCarhart\\OneDrive - Appriss Health LLC\\Desktop\\merged_data_wide.csv'\n",
    "# merged_df.to_csv(output_path_wide, index=False)\n",
    "\n",
    "# Reshape the DataFrame from wide to long format for the specified columns\n",
    "columns_to_reshape = ['DESYNPUF_ID'] + [col + suffix for col in columns_to_sum for suffix in ['_2008', '_2009', '_2010']]\n",
    "df_wide = merged_df[columns_to_reshape]\n",
    "\n",
    "# Use pd.melt to reshape the DataFrame to long format\n",
    "df_long = pd.melt(df_wide, id_vars=['DESYNPUF_ID'],\n",
    "                  value_vars=[col + suffix for col in columns_to_sum for suffix in ['_2008', '_2009', '_2010']],\n",
    "                  var_name='Year_Column', value_name='Value')\n",
    "\n",
    "# Split the 'Year_Column' to extract the year information and the original column name\n",
    "df_long['Year'] = df_long['Year_Column'].str.extract(r'(\\d{4})$')\n",
    "df_long['Column'] = df_long['Year_Column'].str.replace(r'_\\d{4}$', '')\n",
    "\n",
    "# Convert 'Year' to integer\n",
    "df_long['Year'] = pd.to_numeric(df_long['Year'], errors='coerce')\n",
    "\n",
    "# Sum 'Value' by 'Year' and 'DESYNPUF_ID' to create 'annual_cost'\n",
    "annual_cost = df_long.groupby(['DESYNPUF_ID', 'Year'])['Value'].sum().reset_index()\n",
    "annual_cost.rename(columns={'Value': 'annual_cost'}, inplace=True)\n",
    "\n",
    "# Finalize the long format DataFrame to include DESYNPUF_ID, Year, and annual_cost\n",
    "df_long_final = annual_cost\n",
    "\n",
    "# Merge additional columns from 2008 dataset\n",
    "df_long_final = df_long_final.merge(additional_columns_08, on='DESYNPUF_ID', how='left')\n",
    "\n",
    "# Export the long format DataFrame to a CSV file\n",
    "output_path_long = r'C:\\Users\\JoeCarhart\\OneDrive - Appriss Health LLC\\Desktop\\merged_data_long.csv'\n",
    "df_long_final.to_csv(output_path_long, index=False)\n",
    "\n",
    "# Display the first few rows of the resulting DataFrames\n",
    "print(\"Wide format DataFrame:\")\n",
    "print(merged_df.head())\n",
    "print(\"\\nLong format DataFrame:\")\n",
    "print(df_long_final.head())\n",
    "\n",
    "stop_time = time.time()\n",
    "print(\"The code block took {0} seconds to run.\".format(stop_time - start_time))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6426861 entries, 0 to 6426860\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Dtype         \n",
      "---  ------       -----         \n",
      " 0   DESYNPUF_ID  object        \n",
      " 1   Year         int64         \n",
      " 2   annual_cost  float64       \n",
      " 3   Birth_Date   datetime64[ns]\n",
      " 4   Age          int64         \n",
      " 5   Gender       int64         \n",
      " 6   Race         int64         \n",
      " 7   State        int64         \n",
      " 8   County       int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(6), object(1)\n",
      "memory usage: 490.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_long_final.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This code block needs further optimization. It currently takes close to 6 mins to process the diagnosis data for all 20 samples of beneficiary data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long format Diagnoses DataFrame:\n",
      "              DESYNPUF_ID  Year  SP_ALZHDMTA  SP_CHF  SP_CHRNKIDN  SP_CNCR  \\\n",
      "0        00013D2EFD8E45D1  2008            2       2            2        2   \n",
      "1        00016F745862898F  2008            2       2            2        2   \n",
      "2        0001FDD721E223DC  2008            2       2            2        2   \n",
      "3        00021CA6FF03E670  2008            2       2            2        2   \n",
      "4        00024B3D2352D2D0  2008            2       2            2        2   \n",
      "...                   ...   ...          ...     ...          ...      ...   \n",
      "6426856  FFFD961415966F79  2010            2       2            2        2   \n",
      "6426857  FFFDA4E3D602964B  2010            2       2            2        2   \n",
      "6426858  FFFEEB065C259516  2010            2       2            2        2   \n",
      "6426859  FFFFAA8FF082E605  2010            2       1            2        2   \n",
      "6426860  FFFFBC57C82B76C5  2010            2       1            1        2   \n",
      "\n",
      "         SP_COPD  SP_DEPRESSN  SP_DIABETES  SP_ISCHMCHT  SP_OSTEOPRS  \\\n",
      "0              2            2            2            2            2   \n",
      "1              2            2            2            2            2   \n",
      "2              2            2            2            2            2   \n",
      "3              2            2            2            2            2   \n",
      "4              2            2            2            2            1   \n",
      "...          ...          ...          ...          ...          ...   \n",
      "6426856        2            2            2            1            2   \n",
      "6426857        2            2            2            2            2   \n",
      "6426858        2            2            2            2            2   \n",
      "6426859        2            2            1            1            2   \n",
      "6426860        2            2            1            1            1   \n",
      "\n",
      "         SP_RA_OA  SP_STRKETIA  BENE_ESRD_IND  \n",
      "0               2            2              2  \n",
      "1               2            2              2  \n",
      "2               2            2              2  \n",
      "3               2            2              2  \n",
      "4               2            2              2  \n",
      "...           ...          ...            ...  \n",
      "6426856         2            2              2  \n",
      "6426857         2            2              2  \n",
      "6426858         2            2              2  \n",
      "6426859         2            2              2  \n",
      "6426860         2            1              1  \n",
      "\n",
      "[6426861 rows x 14 columns]\n",
      "The code block took 458.9891483783722 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Define the diagnosis columns and prefixes\n",
    "diagnosis_columns = [\n",
    "    'DESYNPUF_ID',\n",
    "    'SP_ALZHDMTA_2008', 'SP_CHF_2008', 'SP_CHRNKIDN_2008', 'SP_CNCR_2008', 'SP_COPD_2008',\n",
    "    'SP_DEPRESSN_2008', 'SP_DIABETES_2008', 'SP_ISCHMCHT_2008', 'SP_OSTEOPRS_2008',\n",
    "    'SP_RA_OA_2008', 'SP_STRKETIA_2008', 'BENE_ESRD_IND_2008',\n",
    "    'SP_ALZHDMTA_2009', 'SP_CHF_2009', 'SP_CHRNKIDN_2009', 'SP_CNCR_2009', 'SP_COPD_2009',\n",
    "    'SP_DEPRESSN_2009', 'SP_DIABETES_2009', 'SP_ISCHMCHT_2009', 'SP_OSTEOPRS_2009',\n",
    "    'SP_RA_OA_2009', 'SP_STRKETIA_2009', 'BENE_ESRD_IND_2009',\n",
    "    'SP_ALZHDMTA_2010', 'SP_CHF_2010', 'SP_CHRNKIDN_2010', 'SP_CNCR_2010', 'SP_COPD_2010',\n",
    "    'SP_DEPRESSN_2010', 'SP_DIABETES_2010', 'SP_ISCHMCHT_2010', 'SP_OSTEOPRS_2010',\n",
    "    'SP_RA_OA_2010', 'SP_STRKETIA_2010', 'BENE_ESRD_IND_2010'\n",
    "]\n",
    "\n",
    "# Create the diagnoses DataFrame from the main DataFrame\n",
    "diagnoses = merged_df[diagnosis_columns]\n",
    "\n",
    "# List of diagnosis prefixes\n",
    "diagnosis_prefixes = [\n",
    "    'SP_ALZHDMTA', 'SP_CHF', 'SP_CHRNKIDN', 'SP_CNCR', 'SP_COPD',\n",
    "    'SP_DEPRESSN', 'SP_DIABETES', 'SP_ISCHMCHT', 'SP_OSTEOPRS',\n",
    "    'SP_RA_OA', 'SP_STRKETIA', 'BENE_ESRD_IND'\n",
    "]\n",
    "\n",
    "# Initialize an empty DataFrame to store the long format data\n",
    "diagnoses_long_list = []\n",
    "\n",
    "# Transform each set of columns to long format and append them to the list\n",
    "for prefix in diagnosis_prefixes:\n",
    "    columns = [f'{prefix}_2008', f'{prefix}_2009', f'{prefix}_2010']\n",
    "    df_long = pd.melt(diagnoses, id_vars=['DESYNPUF_ID'], value_vars=columns,\n",
    "                      var_name='Year', value_name=prefix)\n",
    "    df_long['Year'] = df_long['Year'].str.extract(r'(\\d{4})$').astype(int)\n",
    "    diagnoses_long_list.append(df_long)\n",
    "\n",
    "# Combine all long format DataFrames\n",
    "diagnoses_long = diagnoses_long_list[0]\n",
    "for df_long in diagnoses_long_list[1:]:\n",
    "    diagnoses_long = diagnoses_long.merge(df_long, on=['DESYNPUF_ID', 'Year'], how='outer')\n",
    "\n",
    "# Display the transformed long DataFrame\n",
    "print(\"Long format Diagnoses DataFrame:\")\n",
    "print(diagnoses_long)\n",
    "\n",
    "stop_time = time.time()\n",
    "print(\"The code block took {0} seconds to run.\".format(stop_time - start_time))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6426861 entries, 0 to 6426860\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Dtype \n",
      "---  ------         ----- \n",
      " 0   DESYNPUF_ID    object\n",
      " 1   Year           int32 \n",
      " 2   SP_ALZHDMTA    int64 \n",
      " 3   SP_CHF         int64 \n",
      " 4   SP_CHRNKIDN    int64 \n",
      " 5   SP_CNCR        int64 \n",
      " 6   SP_COPD        int64 \n",
      " 7   SP_DEPRESSN    int64 \n",
      " 8   SP_DIABETES    int64 \n",
      " 9   SP_ISCHMCHT    int64 \n",
      " 10  SP_OSTEOPRS    int64 \n",
      " 11  SP_RA_OA       int64 \n",
      " 12  SP_STRKETIA    int64 \n",
      " 13  BENE_ESRD_IND  int32 \n",
      "dtypes: int32(2), int64(11), object(1)\n",
      "memory usage: 686.5+ MB\n"
     ]
    }
   ],
   "source": [
    "diagnoses_long.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code block took 55.96908164024353 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Merge diagnoses_long to df_long_final by 'DESYNPUF_ID' and 'Year'\n",
    "bene_df = pd.merge(df_long_final, diagnoses_long, on=['DESYNPUF_ID', 'Year'], how='outer')\n",
    "\n",
    "# Drop the 'Year' column\n",
    "bene_df = bene_df.drop(columns=['Year'])\n",
    "\n",
    "# Group by 'DESYNPUF_ID' and aggregate as required\n",
    "agg_dict = {\n",
    "    'Age': 'max',\n",
    "    'Gender': 'max',\n",
    "    'Race': 'max',\n",
    "    'State': 'max',\n",
    "    'County': 'max',\n",
    "    'annual_cost': ['sum', 'mean'],\n",
    "    'SP_ALZHDMTA': 'min',\n",
    "    'SP_CHF': 'min',\n",
    "    'SP_CHRNKIDN': 'min',\n",
    "    'SP_CNCR': 'min',\n",
    "    'SP_COPD': 'min',\n",
    "    'SP_DEPRESSN': 'min',\n",
    "    'SP_DIABETES': 'min',\n",
    "    'SP_ISCHMCHT': 'min',\n",
    "    'SP_OSTEOPRS': 'min',\n",
    "    'SP_RA_OA': 'min',\n",
    "    'SP_STRKETIA': 'min',\n",
    "    'BENE_ESRD_IND': 'min'\n",
    "}\n",
    "\n",
    "# Perform the aggregation\n",
    "bene_df = bene_df.groupby('DESYNPUF_ID').agg(agg_dict).reset_index()\n",
    "\n",
    "# Flatten the MultiIndex columns\n",
    "bene_df.columns = [col[0] if col[1] == '' else '_'.join(col).strip() for col in bene_df.columns]\n",
    "\n",
    "# Remove suffixes '_max' and '_min' from column names\n",
    "bene_df.columns = [col.replace('_max', '').replace('_min', '') for col in bene_df.columns]\n",
    "\n",
    "# Rename the aggregated columns\n",
    "bene_df = bene_df.rename(columns={\n",
    "    'annual_cost_sum': 'total_cost',\n",
    "    'annual_cost_mean': 'average_cost'\n",
    "})\n",
    "\n",
    "# Define the path to save the CSV file for QA\n",
    "output_path = r'C:\\Users\\JoeCarhart\\OneDrive - Appriss Health LLC\\Desktop\\final_merged_data.csv'\n",
    "\n",
    "# Export the final DataFrame to a CSV file\n",
    "bene_df.to_csv(output_path, index=False)\n",
    "\n",
    "stop_time = time.time()\n",
    "print(\"The code block took {0} seconds to run.\".format(stop_time - start_time))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "        DESYNPUF_ID  Age  Gender  Race  State  County  total_cost  \\\n0  00000B48BCF4AD29  100       2     5     10     260    108092.0   \n1  0000141F2FECE9BC   50       2     1     39     560      5308.0   \n2  000022FFDB0BE2C7   85       1     1     24     260       290.0   \n3  00002BE498BED936   83       1     1     36     480         0.0   \n4  00003539A5D77654   80       1     1     24     690       290.0   \n\n   average_cost  SP_ALZHDMTA  SP_CHF  SP_CHRNKIDN  SP_CNCR  SP_COPD  \\\n0  36030.666667            1       1            1        1        2   \n1   1769.333333            2       2            2        2        2   \n2     96.666667            2       2            2        2        2   \n3      0.000000            2       2            2        2        2   \n4     96.666667            2       2            2        2        2   \n\n   SP_DEPRESSN  SP_DIABETES  SP_ISCHMCHT  SP_OSTEOPRS  SP_RA_OA  SP_STRKETIA  \\\n0            1            1            1            1         2            1   \n1            1            2            2            2         2            2   \n2            2            2            2            2         2            2   \n3            2            2            2            2         2            2   \n4            2            2            2            2         2            2   \n\n   BENE_ESRD_IND  \n0              1  \n1              2  \n2              2  \n3              2  \n4              2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DESYNPUF_ID</th>\n      <th>Age</th>\n      <th>Gender</th>\n      <th>Race</th>\n      <th>State</th>\n      <th>County</th>\n      <th>total_cost</th>\n      <th>average_cost</th>\n      <th>SP_ALZHDMTA</th>\n      <th>SP_CHF</th>\n      <th>SP_CHRNKIDN</th>\n      <th>SP_CNCR</th>\n      <th>SP_COPD</th>\n      <th>SP_DEPRESSN</th>\n      <th>SP_DIABETES</th>\n      <th>SP_ISCHMCHT</th>\n      <th>SP_OSTEOPRS</th>\n      <th>SP_RA_OA</th>\n      <th>SP_STRKETIA</th>\n      <th>BENE_ESRD_IND</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000B48BCF4AD29</td>\n      <td>100</td>\n      <td>2</td>\n      <td>5</td>\n      <td>10</td>\n      <td>260</td>\n      <td>108092.0</td>\n      <td>36030.666667</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0000141F2FECE9BC</td>\n      <td>50</td>\n      <td>2</td>\n      <td>1</td>\n      <td>39</td>\n      <td>560</td>\n      <td>5308.0</td>\n      <td>1769.333333</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000022FFDB0BE2C7</td>\n      <td>85</td>\n      <td>1</td>\n      <td>1</td>\n      <td>24</td>\n      <td>260</td>\n      <td>290.0</td>\n      <td>96.666667</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00002BE498BED936</td>\n      <td>83</td>\n      <td>1</td>\n      <td>1</td>\n      <td>36</td>\n      <td>480</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00003539A5D77654</td>\n      <td>80</td>\n      <td>1</td>\n      <td>1</td>\n      <td>24</td>\n      <td>690</td>\n      <td>290.0</td>\n      <td>96.666667</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bene_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inpatient data processing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique IDs: 753231\n",
      "First few rows of the DataFrame:\n",
      "        DESYNPUF_ID           CLM_ID CLM_FROM_DT CLM_THRU_DT  AT_PHYSN_NPI  \\\n",
      "0  00013D2EFD8E45D1  196661176988405  2010-03-12  2010-03-13    3139083564   \n",
      "1  00016F745862898F  196201177000368  2009-04-12  2009-04-18    6476809087   \n",
      "2  00016F745862898F  196661177015632  2009-08-31  2009-09-02     611998537   \n",
      "3  00016F745862898F  196091176981058  2009-09-17  2009-09-20    4971602784   \n",
      "4  00016F745862898F  196261176983265  2010-06-26  2010-07-01    6408400473   \n",
      "\n",
      "   CLM_UTLZTN_DAY_CNT  Year  \n",
      "0                   1  2010  \n",
      "1                   6  2009  \n",
      "2                   2  2009  \n",
      "3                   3  2009  \n",
      "4                   5  2010  \n",
      "The code block took 15.169937133789062 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Define base directory and file pattern\n",
    "base_dir = r'C:\\code_personal_use\\cms\\data\\ip'\n",
    "file_pattern = 'DE1_0_2008_to_2010_Inpatient_Claims_Sample_{}.csv'\n",
    "\n",
    "# Function to load and preprocess a single file\n",
    "def load_and_preprocess_file(file_path):\n",
    "    df = pd.read_csv(file_path, usecols=['DESYNPUF_ID', 'CLM_ID', 'CLM_FROM_DT', 'CLM_THRU_DT', 'AT_PHYSN_NPI', 'CLM_UTLZTN_DAY_CNT'], dtype={'AT_PHYSN_NPI': str})\n",
    "\n",
    "    # Convert CLM_FROM_DT and CLM_THRU_DT to datetime format\n",
    "    df['CLM_FROM_DT'] = pd.to_datetime(df['CLM_FROM_DT'], format='%Y%m%d', errors='coerce')\n",
    "    df['CLM_THRU_DT'] = pd.to_datetime(df['CLM_THRU_DT'], format='%Y%m%d', errors='coerce')\n",
    "\n",
    "    # Drop rows with missing values in CLM_FROM_DT, AT_PHYSN_NPI, and CLM_UTLZTN_DAY_CNT\n",
    "    df = df.dropna(subset=['CLM_FROM_DT', 'AT_PHYSN_NPI', 'CLM_UTLZTN_DAY_CNT'])\n",
    "\n",
    "    # Ensure AT_PHYSN_NPI does not have scientific notation and convert it to integers\n",
    "    df['AT_PHYSN_NPI'] = df['AT_PHYSN_NPI'].apply(lambda x: int(float(x)))\n",
    "\n",
    "    # Convert CLM_UTLZTN_DAY_CNT to integers\n",
    "    df['CLM_UTLZTN_DAY_CNT'] = df['CLM_UTLZTN_DAY_CNT'].astype(int)\n",
    "\n",
    "    # Extract the year as a four-digit number and create a new column 'Year'\n",
    "    df['Year'] = df['CLM_FROM_DT'].dt.year\n",
    "\n",
    "    return df\n",
    "\n",
    "# List to store dataframes\n",
    "dfs = []\n",
    "\n",
    "# Load and preprocess all files\n",
    "for i in range(1, 21):\n",
    "    file_path = os.path.join(base_dir, file_pattern.format(i))\n",
    "    df = load_and_preprocess_file(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "ip_sample_all = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the resulting DataFrame and unique ID counts\n",
    "print(f'Unique IDs: {ip_sample_all[\"DESYNPUF_ID\"].nunique()}')\n",
    "\n",
    "print(\"First few rows of the DataFrame:\")\n",
    "print(ip_sample_all.head())\n",
    "\n",
    "stop_time = time.time()\n",
    "print(\"The code block took {0} seconds to run.\".format(stop_time - start_time))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1319470 entries, 0 to 1319469\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count    Dtype         \n",
      "---  ------              --------------    -----         \n",
      " 0   DESYNPUF_ID         1319470 non-null  object        \n",
      " 1   CLM_ID              1319470 non-null  int64         \n",
      " 2   CLM_FROM_DT         1319470 non-null  datetime64[ns]\n",
      " 3   CLM_THRU_DT         1319470 non-null  datetime64[ns]\n",
      " 4   AT_PHYSN_NPI        1319470 non-null  int64         \n",
      " 5   CLM_UTLZTN_DAY_CNT  1319470 non-null  int32         \n",
      " 6   Year                1319470 non-null  int64         \n",
      "dtypes: datetime64[ns](2), int32(1), int64(3), object(1)\n",
      "memory usage: 65.4+ MB\n"
     ]
    }
   ],
   "source": [
    "ip_sample_all.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code block took 195.87233805656433 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Filter to include only the specific DESYNPUF_ID for EDA and QA\n",
    "# ip_sample_one = ip_sample_one[ip_sample_one['DESYNPUF_ID'] == '00016F745862898F']\n",
    "\n",
    "# Group by DESYNPUF_ID and Year, and perform the required calculations\n",
    "ip_basic_summary = ip_sample_all.groupby(['DESYNPUF_ID']).agg({\n",
    "    'CLM_ID': pd.Series.nunique,  # Count distinct CLM_ID\n",
    "    'AT_PHYSN_NPI': pd.Series.nunique,  # Count distinct AT_PHYSN_NPI\n",
    "    'CLM_UTLZTN_DAY_CNT': 'mean'  # Average CLM_UTLZTN_DAY_CNT\n",
    "}).reset_index()\n",
    "\n",
    "# Rename the columns to be more descriptive\n",
    "ip_basic_summary.columns = ['DESYNPUF_ID', 'Distinct_IP_CLM_ID_Count', 'Distinct_IP_NPI_Count', 'Avg_CLM_UTLZTN_DAY_CNT']\n",
    "\n",
    "stop_time = time.time()\n",
    "print(\"The code block took {0} seconds to run.\".format(stop_time - start_time))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "             DESYNPUF_ID  Distinct_IP_CLM_ID_Count  Distinct_IP_NPI_Count  \\\n0       00000B48BCF4AD29                         3                      3   \n1       0000141F2FECE9BC                         1                      1   \n2       0000525AB30E4DEF                         2                      2   \n3       000064755F16C901                         1                      1   \n4       0000838E2BBC2ADA                         2                      1   \n...                  ...                       ...                    ...   \n753226  FFFFBC57C82B76C5                         2                      2   \n753227  FFFFC23B80C0069F                         1                      1   \n753228  FFFFD21164D5316F                         1                      1   \n753229  FFFFEE90E1B4D0DF                         2                      2   \n753230  FFFFF4859B6D7402                         1                      1   \n\n        Avg_CLM_UTLZTN_DAY_CNT  \n0                     9.333333  \n1                     2.000000  \n2                     8.500000  \n3                     6.000000  \n4                    14.000000  \n...                        ...  \n753226                2.000000  \n753227                6.000000  \n753228                2.000000  \n753229                3.500000  \n753230                3.000000  \n\n[753231 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DESYNPUF_ID</th>\n      <th>Distinct_IP_CLM_ID_Count</th>\n      <th>Distinct_IP_NPI_Count</th>\n      <th>Avg_CLM_UTLZTN_DAY_CNT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000B48BCF4AD29</td>\n      <td>3</td>\n      <td>3</td>\n      <td>9.333333</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0000141F2FECE9BC</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0000525AB30E4DEF</td>\n      <td>2</td>\n      <td>2</td>\n      <td>8.500000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000064755F16C901</td>\n      <td>1</td>\n      <td>1</td>\n      <td>6.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0000838E2BBC2ADA</td>\n      <td>2</td>\n      <td>1</td>\n      <td>14.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>753226</th>\n      <td>FFFFBC57C82B76C5</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>753227</th>\n      <td>FFFFC23B80C0069F</td>\n      <td>1</td>\n      <td>1</td>\n      <td>6.000000</td>\n    </tr>\n    <tr>\n      <th>753228</th>\n      <td>FFFFD21164D5316F</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>753229</th>\n      <td>FFFFEE90E1B4D0DF</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3.500000</td>\n    </tr>\n    <tr>\n      <th>753230</th>\n      <td>FFFFF4859B6D7402</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>753231 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip_basic_summary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Outpatient data processing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique IDs: 1702981\n",
      "First few rows of the DataFrame:\n",
      "        DESYNPUF_ID           CLM_ID CLM_FROM_DT CLM_THRU_DT  AT_PHYSN_NPI  \\\n",
      "0  00013D2EFD8E45D1  542192281063886  2008-09-04  2008-09-04    4824842417   \n",
      "1  00016F745862898F  542272281166593  2009-06-02  2009-06-02    2963419753   \n",
      "2  00016F745862898F  542282281644416  2009-06-23  2009-06-23    5737807753   \n",
      "3  0001FDD721E223DC  542642281250669  2009-10-11  2009-10-11    1233847710   \n",
      "4  00024B3D2352D2D0  542242281386963  2008-07-12  2008-07-12    9688809345   \n",
      "\n",
      "   Year  \n",
      "0  2008  \n",
      "1  2009  \n",
      "2  2009  \n",
      "3  2009  \n",
      "4  2008  \n",
      "The code block took 142.4021863937378 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Define base directory and file pattern\n",
    "base_dir = r'C:\\code_personal_use\\cms\\data\\op'\n",
    "file_pattern = 'DE1_0_2008_to_2010_Outpatient_Claims_Sample_{}.csv'\n",
    "\n",
    "# Function to load and preprocess a single file\n",
    "def load_and_preprocess_file(file_path):\n",
    "    df = pd.read_csv(file_path, usecols=['DESYNPUF_ID', 'CLM_ID', 'CLM_FROM_DT', 'CLM_THRU_DT', 'AT_PHYSN_NPI'], dtype={'AT_PHYSN_NPI': str})\n",
    "\n",
    "    # Convert CLM_FROM_DT and CLM_THRU_DT to datetime format\n",
    "    df['CLM_FROM_DT'] = pd.to_datetime(df['CLM_FROM_DT'], format='%Y%m%d', errors='coerce')\n",
    "    df['CLM_THRU_DT'] = pd.to_datetime(df['CLM_THRU_DT'], format='%Y%m%d', errors='coerce')\n",
    "\n",
    "    # Drop rows with missing values in CLM_FROM_DT and AT_PHYSN_NPI\n",
    "    df = df.dropna(subset=['CLM_FROM_DT', 'AT_PHYSN_NPI'])\n",
    "\n",
    "    # Ensure AT_PHYSN_NPI does not have scientific notation and convert it to integers\n",
    "    df['AT_PHYSN_NPI'] = df['AT_PHYSN_NPI'].apply(lambda x: int(float(x)))\n",
    "\n",
    "    # Extract the year as a four-digit number and create a new column 'Year'\n",
    "    df['Year'] = df['CLM_FROM_DT'].dt.year\n",
    "\n",
    "    return df\n",
    "\n",
    "# List to store dataframes\n",
    "dfs = []\n",
    "\n",
    "# Load and preprocess all files\n",
    "for i in range(1, 21):\n",
    "    file_path = os.path.join(base_dir, file_pattern.format(i))\n",
    "    df = load_and_preprocess_file(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "op_sample_all = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the resulting DataFrame and unique ID counts\n",
    "print(f'Unique IDs: {op_sample_all[\"DESYNPUF_ID\"].nunique()}')\n",
    "\n",
    "print(\"First few rows of the DataFrame:\")\n",
    "print(op_sample_all.head())\n",
    "\n",
    "stop_time = time.time()\n",
    "print(\"The code block took {0} seconds to run.\".format(stop_time - start_time))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15474093 entries, 0 to 15474092\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Dtype         \n",
      "---  ------        -----         \n",
      " 0   DESYNPUF_ID   object        \n",
      " 1   CLM_ID        int64         \n",
      " 2   CLM_FROM_DT   datetime64[ns]\n",
      " 3   CLM_THRU_DT   datetime64[ns]\n",
      " 4   AT_PHYSN_NPI  int64         \n",
      " 5   Year          int64         \n",
      "dtypes: datetime64[ns](2), int64(3), object(1)\n",
      "memory usage: 708.3+ MB\n"
     ]
    }
   ],
   "source": [
    "op_sample_all.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Filter to include only the specific DESYNPUF_ID for EDA and QA\n",
    "# op_sample_one = op_sample_one[op_sample_one['DESYNPUF_ID'] == '00016F745862898F']\n",
    "\n",
    "# Group by DESYNPUF_ID and Year, and perform the required calculations\n",
    "op_basic_summary = op_sample_all.groupby(['DESYNPUF_ID']).agg({\n",
    "    'CLM_ID': pd.Series.nunique,  # Count distinct CLM_ID\n",
    "    'AT_PHYSN_NPI': pd.Series.nunique,  # Count distinct AT_PHYSN_NPI\n",
    "}).reset_index()\n",
    "\n",
    "# Rename the columns to be more descriptive\n",
    "op_basic_summary.columns = ['DESYNPUF_ID', 'Distinct_OP_CLM_ID_Count', 'Distinct_OP_NPI_Count']\n",
    "\n",
    "stop_time = time.time()\n",
    "print(\"The code block took {0} seconds to run.\".format(stop_time - start_time))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "op_basic_summary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A few quick checks before combining the benecificary data, inpatient data, and outpatient data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bene_df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ip_basic_summary.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "op_basic_summary.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Merge the three data sets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Select the specified columns from ip_basic_summary and op_basic_summary\n",
    "ip_selected = ip_basic_summary[['DESYNPUF_ID', 'Distinct_IP_CLM_ID_Count', 'Distinct_IP_NPI_Count', 'Avg_CLM_UTLZTN_DAY_CNT']]\n",
    "op_selected = op_basic_summary[['DESYNPUF_ID', 'Distinct_OP_CLM_ID_Count', 'Distinct_OP_NPI_Count']]\n",
    "\n",
    "\n",
    "# Merge bene and ip data\n",
    "bene_ip = pd.merge(bene_df, ip_selected, on=['DESYNPUF_ID'], how='left')\n",
    "\n",
    "\n",
    "# Merge the result with outpatient data\n",
    "final_df = pd.merge(bene_ip, op_selected, on=['DESYNPUF_ID'], how='left')\n",
    "\n",
    "\n",
    "# Replace NaNs with 0\n",
    "final_df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "stop_time = time.time()\n",
    "print(\"The code block took {0} seconds to run.\".format(stop_time - start_time))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Perform predictive modeling**\n",
    "\n",
    "I have chosen to use the XGBoost regression model for this particular predictive project.\n",
    "\n",
    "\n",
    "XGBoost (Extreme Gradient Boosting) is a powerful machine learning algorithm known for its performance and efficiency. Below are several benefits of using XGBoost for regression tasks compared to other methods:\n",
    "\n",
    "Performance and Accuracy\n",
    "* XGBoost often outperforms other algorithms in terms of predictive accuracy. It efficiently handles large datasets and can model complex relationships and can handle missing data gracefully by learning the best direction to handle missing values in the decision trees.\n",
    "\n",
    "Regularization\n",
    "* XGBoost incorporates both L1 (Lasso) and L2 (Ridge) regularization, which helps prevent overfitting and improves model generalization.\n",
    "\n",
    "Flexibility\n",
    "* XGBoost allows for the implementation of custom loss functions, providing flexibility to tailor the model to specific problem requirements and offers a wide range of parameters that can be tuned to improve model performance, such as learning rate, tree depth, and subsampling ratios.\n",
    "\n",
    "Efficiency and Scalability\n",
    "* XGBoost supports parallel processing, making it much faster than other gradient boosting implementations and can be run on distributed systems, enabling the processing of very large datasets that do not fit into memory.\n",
    "\n",
    "Tree Pruning and Sparsity Aware\n",
    "* XGBoost uses a more sophisticated tree pruning algorithm that reduces overfitting and handles sparse data efficiently, which is particularly beneficial for datasets with missing values or categorical features that have been one-hot encoded.\n",
    "\n",
    "Cross-Validation\n",
    "* Built-in Cross-Validation: XGBoost has built-in cross-validation capabilities, making it easier to assess model performance and prevent overfitting.\n",
    "\n",
    "Feature Importance\n",
    "* Feature Importance Analysis: XGBoost provides useful metrics for feature importance, which helps in understanding the underlying data and the factors influencing the predictions.\n",
    "\n",
    "Comparison with Other Methods\n",
    "* Linear Regression: XGBoost can capture non-linear relationships which linear regression cannot.\n",
    "* Random Forests: XGBoost often provides better performance and can handle bias-variance trade-off more effectively due to its boosting nature.\n",
    "* Neural Networks: While neural networks can also model complex relationships, they typically require more computational resources and longer training times. XGBoost tends to be faster and easier to tune.\n",
    "* Other Boosting Methods (e.g., AdaBoost): XGBoost typically offers better performance due to its regularization techniques and advanced handling of missing data and sparsity."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's convert to traditional dummy coded values for easier end-user interpretation.\n",
    "# Columns to transform\n",
    "columns_to_transform = ['SP_ALZHDMTA', 'SP_CHF', 'SP_CHRNKIDN', 'SP_CNCR', 'SP_COPD',\n",
    "                        'SP_DEPRESSN', 'SP_DIABETES', 'SP_ISCHMCHT', 'SP_OSTEOPRS',\n",
    "                        'SP_RA_OA', 'SP_STRKETIA', 'BENE_ESRD_IND']\n",
    "\n",
    "# Transform the values\n",
    "final_df[columns_to_transform] = final_df[columns_to_transform].replace({2: 0, 1: 1})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "train, test = train_test_split(final_df, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train.columns.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train = train[[ 'Age',\n",
    " 'Gender',\n",
    " 'Race',\n",
    " 'State',\n",
    " 'County',\n",
    " 'SP_ALZHDMTA',\n",
    " 'SP_CHF',\n",
    " 'SP_CHRNKIDN',\n",
    " 'SP_CNCR',\n",
    " 'SP_COPD',\n",
    " 'SP_DEPRESSN',\n",
    " 'SP_DIABETES',\n",
    " 'SP_ISCHMCHT',\n",
    " 'SP_OSTEOPRS',\n",
    " 'SP_RA_OA',\n",
    " 'SP_STRKETIA',\n",
    " 'BENE_ESRD_IND',\n",
    " 'Distinct_IP_CLM_ID_Count',\n",
    " 'Distinct_IP_NPI_Count',\n",
    " 'Avg_CLM_UTLZTN_DAY_CNT',\n",
    " 'Distinct_OP_CLM_ID_Count',\n",
    " 'Distinct_OP_NPI_Count',\n",
    " 'average_cost',]]\n",
    "y_train = train[['total_cost']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test = test[[ 'Age',\n",
    " 'Gender',\n",
    " 'Race',\n",
    " 'State',\n",
    " 'County',\n",
    " 'SP_ALZHDMTA',\n",
    " 'SP_CHF',\n",
    " 'SP_CHRNKIDN',\n",
    " 'SP_CNCR',\n",
    " 'SP_COPD',\n",
    " 'SP_DEPRESSN',\n",
    " 'SP_DIABETES',\n",
    " 'SP_ISCHMCHT',\n",
    " 'SP_OSTEOPRS',\n",
    " 'SP_RA_OA',\n",
    " 'SP_STRKETIA',\n",
    " 'BENE_ESRD_IND',\n",
    " 'Distinct_IP_CLM_ID_Count',\n",
    " 'Distinct_IP_NPI_Count',\n",
    " 'Avg_CLM_UTLZTN_DAY_CNT',\n",
    " 'Distinct_OP_CLM_ID_Count',\n",
    " 'Distinct_OP_NPI_Count',\n",
    " 'average_cost',]]\n",
    "y_test = test[['total_cost']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train.shape, y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the XGBoost model\n",
    "model = XGBRegressor(\n",
    "    objective='reg:squarederror',  # Specify regression task\n",
    "    eval_metric='rmse',            # Root Mean Squared Error\n",
    "    max_depth=3,                   # Maximum tree depth\n",
    "    eta=0.1,                       # Learning rate\n",
    "    subsample=0.8,                 # Subsample ratio of training instances\n",
    "    colsample_bytree=0.8,          # Subsample ratio of columns when constructing each tree\n",
    "    n_estimators=100,              # Number of boosting rounds\n",
    "    # early_stopping_rounds=10       # Early stopping rounds\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the  outcome and covariates for cross-validation\n",
    "# Separate the features and the target\n",
    "X = final_df.drop(columns=['total_cost', 'DESYNPUF_ID'])\n",
    "y = final_df['total_cost']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Perform K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_results = cross_val_score(model, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert negative MSE to positive\n",
    "cv_results = -cv_results\n",
    "\n",
    "print(f'Cross-Validation MSE: {cv_results}')\n",
    "print(f'Mean Cross-Validation MSE: {np.mean(cv_results)}')\n",
    "print(f'Standard deviation of Cross-Validation Score: {np.std(cv_results)}')\n",
    "\n",
    "# Plot cross-validation results\n",
    "plt.figure(figsize=(8, 6), facecolor='white')  # Set the figure background color to white\n",
    "ax = plt.gca()\n",
    "ax.set_facecolor('white')  # Set the axes background color to white\n",
    "\n",
    "# Create the boxplot\n",
    "plt.boxplot(cv_results, vert=False)\n",
    "plt.xlabel('Mean Squared Error')\n",
    "plt.title('Cross-Validation Results')\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)  # Optional: Add grid lines for better readability\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**The basics:**\n",
    "\n",
    "Performance Consistency: The boxplot helps visualize the consistency of our model's performance across different folds of the cross-validation. A tight box and short whiskers indicate consistent performance, whereas a wide box and long whiskers indicate more variability.\n",
    "\n",
    "Central Tendency and Spread: The median and IQR provide insight into the central tendency and spread of the cross-validation results.\n",
    "\n",
    "Potential Issues: Outliers highlight potential issues or variations in performance that might need further investigation. They can be caused by particular subsets of the data that are more challenging to predict.\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "Range of MSE Values: The MSE values range approximately from 3.4e6 to 4.2e6.\n",
    "\n",
    "Median MSE: The median MSE value appears to be close to the center of the IQR box, indicating a relatively symmetrical distribution of errors within the central 50% of the data.\n",
    "\n",
    "Outliers: The presence of outliers suggests that in some folds, the model performed significantly better or worse compared to the majority of the folds."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train.values.ravel())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Predict on the validation set\n",
    "y_pred = model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test.loc[:,'predicted_2011_cost'] = y_pred.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate performance metrics on the test set\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'MAE: {mae}, MSE: {mse}, RMSE: {rmse}, R2: {r2}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mean Absolute Error (MAE): Average absolute difference between predicted and actual values.\n",
    "\n",
    "Mean Squared Error (MSE): Lower values indicate better performance.\n",
    "\n",
    "Root Mean Squared Error (RMSE): Similar to MSE but in the same units as the target variable. So, the model performs pretty well since we are trying to predict total cost and the units here are dollars ($1,860.11)\n",
    "\n",
    "R-squared (R²): Proportion of variance explained by the model (higher is better)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select all features\n",
    "    fs = SelectKBest(score_func=f_classif, k='all')\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train.values.ravel())\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "\n",
    "# get feature scores and names\n",
    "feature_scores = fs.scores_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# combine names and scores into a list of tuples\n",
    "features_and_scores = list(zip(feature_names, feature_scores))\n",
    "\n",
    "# sort the list of tuples in descending order of scores\n",
    "features_and_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# print the sorted feature scores with their names\n",
    "for name, score in features_and_scores:\n",
    "    print(f'Feature {name}: {score}')\n",
    "\n",
    "# plot the sorted scores\n",
    "sorted_names = [x[0] for x in features_and_scores]\n",
    "sorted_scores = [x[1] for x in features_and_scores]\n",
    "\n",
    "plt.figure(figsize=(12, 10))  # Increase the figure size\n",
    "plt.bar(sorted_names, sorted_scores)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create figure\n",
    "# fig, ax = plt.subplots(figsize=(12, 10))  # Adjust the figsize as needed\n",
    "# plot_importance(model, ax=ax)\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate the threshold for the top 10% of predictions\n",
    "threshold = np.percentile(test['predicted_2011_cost'], 90)  # Top 10%\n",
    "\n",
    "# Identify high-risk patients with predictions in the top 10%\n",
    "high_risk_patients = test[test['predicted_2011_cost'] >= threshold]\n",
    "\n",
    "# Extract DESYNPUF_ID and prediction for high-risk patients\n",
    "high_risk_patients_list = high_risk_patients[['DESYNPUF_ID', 'predicted_2011_cost']]\n",
    "\n",
    "# Define the file path for the output CSV file\n",
    "file_path = r'C:\\Users\\JoeCarhart\\OneDrive - Appriss Health LLC\\Desktop\\high_risk_patients.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "high_risk_patients_list.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"High-risk patients list saved to {file_path}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "high_risk_patients_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ]
}